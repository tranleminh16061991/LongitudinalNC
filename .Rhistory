CI_U = map_dbl(stats_list1, ~.x$ci[2]),
Pvalue = map_dbl(stats_list1, ~.x$pval)
)
tab1_df <- tab1_df %>% mutate(Pvalue_FDR = p.adjust(Pvalue, method="fdr"))
tab1 <- df_baseline %>%
select(all_of(c(group_var, vars_table1))) %>%
tbl_summary(by = all_of(group_var),
type = all_continuous() ~ c("mean", "sd", "median", "IQR"),
missing_text = "(missing)") %>%
add_p(
test = list(all_continuous() ~ "t.test",
all_categorical() ~ "chisq.test"),
pvalue_fun = ~formatC(.x, digits=3, format="f")
) %>%
add_stat_label() %>%
add_n() %>%
modify_header(label ~ "**Variable**")
# ---- Libraries ----
library(dplyr)
library(gtsummary)
library(flextable)
library(effsize)
library(emmeans)
library(broom)
library(purrr)
library(DescTools)
output_dir <- "Baseline_Results"
if (!dir.exists(output_dir)) dir.create(output_dir)
# ---- 1. Data Preparation: Baseline Only ----
df_baseline <- df4 %>%
filter(Change_Type %in% c("StableCN", "CNtransitMCI")) %>%
group_by(USUBJID) %>%
filter(datetest == min(datetest)) %>%
ungroup()
df_baseline$SEX <- factor(df_baseline$SEX)
df_baseline$Change_Type <- factor(df_baseline$Change_Type, levels = c("StableCN", "CNtransitMCI"))
group_var <- "Change_Type"
# ---- 2. Helper for Stats, Effect Size, Test Selection ----
get_test_and_effect <- function(x, g) {
# Remove missings
idx <- which(!is.na(x) & !is.na(g))
x <- x[idx]; g <- g[idx]
vals <- list(test=NA, smd=NA, pval=NA, ci_l=NA, ci_u=NA, effect=NA)
if(length(unique(g))!=2 || length(x) < 2) return(vals)
# Categorical
if (is.factor(x) || is.character(x)) {
tbl <- table(x, g)
use_fisher <- any(tbl < 5)
pval <- if(use_fisher) fisher.test(tbl)$p.value else chisq.test(tbl)$p.value
eff_val <- if(nlevels(as.factor(x))==2) {
# Cohen's h for dichotomous
counts <- table(x, g)
p1 <- prop.table(counts,2)[1,1]
p2 <- prop.table(counts,2)[1,2]
2*abs(asin(sqrt(p1))-asin(sqrt(p2)))
} else {
suppressWarnings(tryCatch(CramerV(tbl, ci=FALSE), error=function(e) NA))
}
return(list(test=ifelse(use_fisher,"Fisher","Chi2"),
smd=NA, pval=pval, ci_l=NA, ci_u=NA, effect=eff_val))
}
# Numeric
norm1 <- if (sum(g=="StableCN")>2) shapiro.test(x[g=="StableCN"])$p.value > 0.05 else FALSE
norm2 <- if (sum(g=="CNtransitMCI")>2) shapiro.test(x[g=="CNtransitMCI"])$p.value > 0.05 else FALSE
if (norm1 & norm2) {
ttest <- t.test(x ~ g)
eff <- effsize::cohen.d(x, g, hedges.correction=TRUE, conf.level=0.95)
return(list(test="t-test", smd=eff$estimate, pval=ttest$p.value,
ci_l=eff$conf.int[1], ci_u=eff$conf.int[2], effect=eff$estimate))
} else {
wtest <- wilcox.test(x ~ g)
eff <- effsize::cohen.d(x, g, hedges.correction=TRUE, conf.level=0.95)
return(list(test="Wilcoxon", smd=eff$estimate, pval=wtest$p.value,
ci_l=eff$conf.int[1], ci_u=eff$conf.int[2], effect=eff$estimate))
}
}
# ---- 3. Table 1: Demographics & Cognition ----
vars_table1 <- c('SEX','AGE','EDUYR','gds','kdsq','visit_count','MMSE',
'SNSB_attention','SNSB_language','SNSB_visuospatial',
'SNSB_memory','SNSB_frontal')
stats_table1 <- map(vars_table1, ~get_test_and_effect(df_baseline[[.x]], df_baseline$Change_Type))
tab1_df <- tibble(
Variable = vars_table1,
Test = map_chr(stats_table1, ~.x$test),
SMD = map_dbl(stats_table1, ~.x$smd),
Effect = map_dbl(stats_table1, ~.x$effect),
CI_L = map_dbl(stats_table1, ~.x$ci_l),
CI_U = map_dbl(stats_table1, ~.x$ci_u),
Pvalue = map_dbl(stats_table1, ~.x$pval)
)
tab1_df <- tab1_df %>% mutate(Pvalue_FDR = p.adjust(Pvalue, method="fdr"))
write.csv(tab1_df, file.path(output_dir, "table1_stats_full.csv"), row.names=FALSE)
tab1 <- df_baseline %>%
select(all_of(c(group_var, vars_table1))) %>%
tbl_summary(by = all_of(group_var),
type = all_continuous() ~ c("mean", "sd", "median", "IQR"),
missing_text = "(missing)") %>%
add_n() %>%
modify_header(label ~ "**Variable**")
# ---- Libraries ----
library(dplyr)
library(gtsummary)
library(flextable)
library(effsize)
library(emmeans)
library(broom)
library(purrr)
library(DescTools)
output_dir <- "Baseline_Results"
if (!dir.exists(output_dir)) dir.create(output_dir)
# ---- 1. Data Preparation: Baseline Only ----
df_baseline <- df4 %>%
filter(Change_Type %in% c("StableCN", "CNtransitMCI")) %>%
group_by(USUBJID) %>%
filter(datetest == min(datetest)) %>%
ungroup()
df_baseline$SEX <- factor(df_baseline$SEX)
df_baseline$Change_Type <- factor(df_baseline$Change_Type, levels = c("StableCN", "CNtransitMCI"))
group_var <- "Change_Type"
# ---- 2. Safe Helper for Stats/effect size/test selection ----
get_stats <- function(x, g) {
idx <- which(!is.na(x) & !is.na(g))
x <- x[idx]; g <- g[idx]
result <- list(test = NA, smd = NA, pval = NA, ci_l = NA, ci_u = NA, effect = NA)
# Only compare two groups
if(length(unique(g)) != 2 || length(x) < 2) return(result)
# Categorical
if(is.factor(x) || is.character(x)) {
levels_x <- levels(as.factor(x))
tbl <- table(x, g)
use_fisher <- any(tbl < 5)
p <- if(use_fisher) fisher.test(tbl)$p.value else chisq.test(tbl)$p.value
# Binary/dichotomous categorical variable
if(length(levels_x) == 2) {
# Cohen's h
counts <- table(x, g)
prop1 <- if(ncol(counts) >= 1) prop.table(counts,2)[1,1] else 0
prop2 <- if(ncol(counts) >= 2) prop.table(counts,2)[1,2] else 0
eff <- 2 * abs(asin(sqrt(prop1)) - asin(sqrt(prop2)))
} else {
eff <- suppressWarnings(tryCatch(CramerV(tbl, ci = FALSE), error=function(e) NA))
}
return(list(test = ifelse(use_fisher, "Fisher", "Chi2"),
smd = NA, pval = p, ci_l = NA, ci_u = NA, effect = eff))
}
# Numeric
is_norm1 <- if(sum(g == "StableCN") > 2) shapiro.test(x[g == "StableCN"])$p.value > 0.05 else FALSE
is_norm2 <- if(sum(g == "CNtransitMCI") > 2) shapiro.test(x[g == "CNtransitMCI"])$p.value > 0.05 else FALSE
if(is_norm1 & is_norm2) {
ttest <- t.test(x ~ g)
eff <- effsize::cohen.d(x, g, hedges.correction = TRUE, conf.level = 0.95)
return(list(test = "t-test", smd = eff$estimate, pval = ttest$p.value,
ci_l = eff$conf.int[1], ci_u = eff$conf.int[2], effect = eff$estimate))
} else {
wtest <- wilcox.test(x ~ g)
eff <- effsize::cohen.d(x, g, hedges.correction = TRUE, conf.level = 0.95)
return(list(test = "Wilcoxon", smd = eff$estimate, pval = wtest$p.value,
ci_l = eff$conf.int[1], ci_u = eff$conf.int[2], effect = eff$estimate))
}
}
# ---- 3. Table 1: Demographics & Cognition ----
vars_table1 <- c('SEX','AGE','EDUYR','gds','kdsq','visit_count','MMSE',
'SNSB_attention','SNSB_language','SNSB_visuospatial',
'SNSB_memory','SNSB_frontal')
stats_table1 <- map(vars_table1, ~get_stats(df_baseline[[.x]], df_baseline$Change_Type))
tab1_df <- tibble(
Variable = vars_table1,
Test = map_chr(stats_table1, ~.x$test),
SMD = map_dbl(stats_table1, ~.x$smd),
Effect = map_dbl(stats_table1, ~.x$effect),
CI_L = map_dbl(stats_table1, ~.x$ci_l),
CI_U = map_dbl(stats_table1, ~.x$ci_u),
Pvalue = map_dbl(stats_table1, ~.x$pval)
)
tab1_df <- tab1_df %>% mutate(Pvalue_FDR = p.adjust(Pvalue, method="fdr"))
write.csv(tab1_df, file.path(output_dir, "table1_stats_full.csv"), row.names=FALSE)
tab1 <- df_baseline %>%
select(all_of(c(group_var, vars_table1))) %>%
tbl_summary(by = all_of(group_var),
type = all_continuous() ~ c("mean", "sd", "median", "IQR"),
missing_text = "(missing)") %>%
add_n() %>%
modify_header(label ~ "**Variable**")
# ---- Libraries ----
library(dplyr)
library(tableone)
library(effsize)
library(emmeans)
library(tibble)
library(DescTools) # for Cramér's V and CI
output_dir <- "Baseline_Results"
if (!dir.exists(output_dir)) dir.create(output_dir)
### --- Data Preparation: get baseline per subject ---
df_baseline <- df4 %>%
filter(Change_Type %in% c("StableCN", "CNtransitMCI")) %>%
group_by(USUBJID) %>%
filter(datetest == min(datetest)) %>%
ungroup()
df_baseline$SEX <- as.factor(df_baseline$SEX)
df_baseline$Change_Type <- factor(df_baseline$Change_Type, levels = c("StableCN", "CNtransitMCI"))
group_var <- "Change_Type"
# ---- Table 1: Demographics & Cognition ----
vars_table1 <- c('SEX','AGE','EDUYR','gds','kdsq','visit_count','MMSE',
'SNSB_attention','SNSB_language','SNSB_visuospatial',
'SNSB_memory','SNSB_frontal')
tab1 <- CreateTableOne(vars = vars_table1, strata = group_var, data = df_baseline, test = FALSE)
get_missing_pct <- function(x, g) {
res <- tapply(is.na(x), g, mean)
res[is.na(res)] <- 0
res * 100
}
table1stats <- lapply(vars_table1, function(v) {
x <- df_baseline[[v]]
g <- df_baseline[[group_var]]
miss_pct <- get_missing_pct(x, g)
if (length(unique(g)) != 2) return(data.frame(
Variable = v, Type = NA, Pvalue = NA, SMD = NA, SMD_L = NA, SMD_U = NA, EffectSize = NA,
Miss_StableCN = NA, Miss_CNtransitMCI = NA))
if (is.factor(x) | is.character(x)) {
tbl <- table(x, g)
use_fisher <- any(tbl < 5)
pval <- if (use_fisher) fisher.test(tbl)$p.value else chisq.test(tbl)$p.value
# Cramér's V or Cohen's h for binary
es <- tryCatch({
if (nlevels(as.factor(x))==2) {
counts <- table(x, g)
p1 <- prop.table(counts,2)[1,1]
p2 <- prop.table(counts,2)[1,2]
2*abs(asin(sqrt(p1))-asin(sqrt(p2)))
} else {
DescTools::CramerV(tbl, ci = FALSE)
}
}, error=function(e) NA)
return(data.frame(
Variable = v, Type = "cat", Pvalue = pval, SMD = NA, SMD_L = NA, SMD_U = NA, EffectSize = round(es, 3),
Miss_StableCN = round(miss_pct["StableCN"], 2), Miss_CNtransitMCI = round(miss_pct["CNtransitMCI"],2)
))
}
# For numeric variables, Cohen's d (with 95% CI)
is_norm <- tryCatch((shapiro.test(na.omit(x))$p.value > 0.05), error=function(e) FALSE)
test_result <- if (is_norm) t.test(x ~ g) else wilcox.test(x ~ g)
cd <- effsize::cohen.d(x, g, hedges.correction = TRUE, conf.level = 0.95)
return(data.frame(
Variable = v, Type = "num", Pvalue = test_result$p.value, SMD = cd$estimate, SMD_L = cd$conf.int[1], SMD_U = cd$conf.int[2], EffectSize = cd$estimate,
Miss_StableCN = round(miss_pct["StableCN"],2), Miss_CNtransitMCI = round(miss_pct["CNtransitMCI"],2)))
})
df_table1stats <- bind_rows(table1stats)
# Export Table 1
write.csv(print(tab1, quote = TRUE, noSpaces = TRUE), file.path(output_dir,"table1_baseline.csv"))
write.csv(df_table1stats, file.path(output_dir, "table1_baseline_stats_full.csv"), row.names = FALSE)
cat("Table 1 exported as .csv files in", output_dir, "\n")
# ---- Table 2: Anthropometry & Body Composition (Adjusted) ----
vars_table2 <- c('height','weight','Waistcir','Hipcir','bmi','ac','whr',
'pbcm','pbf','bmr','tbw_ffm','ecw_tcw','PA50_total')
covars <- c("AGE", "SEX", "EDUYR")
units_table2 <- c(height = "cm", weight = "kg", Waistcir = "cm", Hipcir = "cm", sysbp = "mmHg", diabp = "mmHg",
bmi = "kg/m2", ac = "", whr = "", pbcm = "%", pbf = "%", bmr = "kcal", tbw_ffm = "%", ecw_tcw = "%", PA50_total = "degree")
get_sample_size <- function(df, v, lvl) sum(!is.na(df[[v]]) & df[[group_var]] == lvl)
get_missing_pct_tbl <- function(df, v, lvl) mean(is.na(df[[v]]) & df[[group_var]] == lvl) * 100
get_ancova_table <- function(varlist, groupvar, covars, df, units = NULL) {
lapply(varlist, function(v) {
fml <- as.formula(paste(v, "~", groupvar, "+", paste(covars, collapse = " + ")))
model <- lm(fml, data = df, na.action = na.exclude)
emm <- emmeans(model, groupvar)
summary_emm <- summary(emm, level = 0.95)
contrasts <- summary(contrast(emm, method = "pairwise"), infer = TRUE)
aovm <- tryCatch(anova(model), error = function(e) NULL)
eta2 <- tryCatch({
ss_group <- aovm[groupvar, "Sum Sq"]
ss_total <- sum(aovm[,"Sum Sq"])
ss_group/ss_total
}, error = function(e) NA)
adj_r2 <- tryCatch(summary(model)$adj.r.squared, error = function(e) NA)
g1 <- levels(df[[group_var]])[1]
g2 <- levels(df[[group_var]])[2]
n1 <- get_sample_size(df, v, g1)
n2 <- get_sample_size(df, v, g2)
miss1 <- get_missing_pct_tbl(df, v, g1)
miss2 <- get_missing_pct_tbl(df, v, g2)
tibble(
Variable = v,
Unit = if (!is.null(units) && !is.na(units[v])) units[v] else "",
N_StableCN = n1,
N_CNtransitMCI = n2,
StableCN_AdjMean_CI = sprintf("%.2f (%.2f, %.2f)", summary_emm$emmean[summary_emm[[groupvar]] == g1],
summary_emm$lower.CL[summary_emm[[groupvar]] == g1],
summary_emm$upper.CL[summary_emm[[groupvar]] == g1]),
CNtransitMCI_AdjMean_CI = sprintf("%.2f (%.2f, %.2f)", summary_emm$emmean[summary_emm[[groupvar]] == g2],
summary_emm$lower.CL[summary_emm[[groupvar]] == g2],
summary_emm$upper.CL[summary_emm[[groupvar]] == g2]),
Diff_CI = sprintf("%.2f (%.2f, %.2f)", contrasts$estimate[1], contrasts$lower.CL[1], contrasts$upper.CL[1]),
SE = round(contrasts$SE[1],2),
PValue = round(contrasts$p.value[1],4),
EtaSq = round(eta2,3),
Adj_R2 = round(adj_r2,3),
Miss_StableCN = round(miss1,2),
Miss_CNtransitMCI = round(miss2,2)
)
}) %>% bind_rows()
}
tbl2_journal <- get_ancova_table(vars_table2, group_var, covars, df_baseline, units_table2)
write.csv(tbl2_journal, file.path(output_dir, "table2_journalformat_full.csv"), row.names = FALSE)
cat("Table 2 exported as .csv file in", output_dir, "\n")
# ---- Table 3: Segmental Variables (Adjusted) ----
vars_table3 <- c('ECW_ICW_upper','ECW_ICW_lower','Water_Lean_upper','Water_Lean_lower',
'R_upper','R_lower','Xc_upper','Xc_lower','PA_upper','PA_lower',
'R_H_upper','R_H_lower','Xc_H_upper','Xc_H_lower')
units_table3 <- c(
ECW_ICW_upper = "%", ECW_ICW_lower = "%", Water_Lean_upper = "%", Water_Lean_lower = "%",
R_upper = "Ohm", R_lower = "Ohm", Xc_upper = "Ohm", Xc_lower = "Ohm",
PA_upper = "degree", PA_lower = "degree", R_H_upper = "Ohm", R_H_lower = "Ohm",
Xc_H_upper = "Ohm", Xc_H_lower = "Ohm"
)
tbl3_journal <- get_ancova_table(vars_table3, group_var, covars, df_baseline, units_table3)
write.csv(tbl3_journal, file.path(output_dir, "table3_journalformat_full.csv"), row.names = FALSE)
cat("Table 3 exported as .csv file in", output_dir, "\n")
# ---- Libraries ----
library(dplyr)
library(tableone)
library(effsize)
library(emmeans)
library(tibble)
library(DescTools) # for Cramér's V and CI
output_dir <- "Baseline_Results"
if (!dir.exists(output_dir)) dir.create(output_dir)
### --- Data Preparation: get baseline per subject ---
df_baseline <- df4 %>%
filter(Change_Type %in% c("StableCN", "CNtransitMCI")) %>%
group_by(USUBJID) %>%
filter(datetest == min(datetest)) %>%
ungroup()
df_baseline$SEX <- as.factor(df_baseline$SEX)
df_baseline$Change_Type <- factor(df_baseline$Change_Type, levels = c("StableCN", "CNtransitMCI"))
group_var <- "Change_Type"
# ---- Table 1: Demographics & Cognition ----
vars_table1 <- c('SEX','AGE','EDUYR','gds','kdsq','visit_count','MMSE',
'SNSB_attention','SNSB_language','SNSB_visuospatial',
'SNSB_memory','SNSB_frontal')
tab1 <- CreateTableOne(vars = vars_table1, strata = group_var, data = df_baseline, test = FALSE)
get_missing_pct <- function(x, g) {
res <- tapply(is.na(x), g, mean)
res[is.na(res)] <- 0
res * 100
}
table1stats <- lapply(vars_table1, function(v) {
x <- df_baseline[[v]]
g <- df_baseline[[group_var]]
miss_pct <- get_missing_pct(x, g)
if (length(unique(g)) != 2) return(data.frame(
Variable = v, Type = NA, Pvalue = NA, SMD = NA, SMD_L = NA, SMD_U = NA, EffectSize = NA,
Miss_StableCN = NA, Miss_CNtransitMCI = NA))
if (is.factor(x) | is.character(x)) {
tbl <- table(x, g)
use_fisher <- any(tbl < 5)
pval <- if (use_fisher) fisher.test(tbl)$p.value else chisq.test(tbl)$p.value
# Cramér's V or Cohen's h for binary
es <- tryCatch({
if (nlevels(as.factor(x))==2) {
counts <- table(x, g)
p1 <- prop.table(counts,2)[1,1]
p2 <- prop.table(counts,2)[1,2]
2*abs(asin(sqrt(p1))-asin(sqrt(p2)))
} else {
DescTools::CramerV(tbl, ci = FALSE)
}
}, error=function(e) NA)
return(data.frame(
Variable = v, Type = "cat", Pvalue = pval, SMD = NA, SMD_L = NA, SMD_U = NA, EffectSize = round(es, 3),
Miss_StableCN = round(miss_pct["StableCN"], 2), Miss_CNtransitMCI = round(miss_pct["CNtransitMCI"],2)
))
}
# For numeric variables, Cohen's d (with 95% CI)
is_norm <- tryCatch((shapiro.test(na.omit(x))$p.value > 0.05), error=function(e) FALSE)
test_result <- if (is_norm) t.test(x ~ g) else wilcox.test(x ~ g)
cd <- effsize::cohen.d(x, g, hedges.correction = TRUE, conf.level = 0.95)
return(data.frame(
Variable = v, Type = "num", Pvalue = test_result$p.value, SMD = cd$estimate, SMD_L = cd$conf.int[1], SMD_U = cd$conf.int[2], EffectSize = cd$estimate,
Miss_StableCN = round(miss_pct["StableCN"],2), Miss_CNtransitMCI = round(miss_pct["CNtransitMCI"],2)))
})
df_table1stats <- bind_rows(table1stats)
# Export Table 1
write.csv(print(tab1, quote = TRUE, noSpaces = TRUE), file.path(output_dir,"table1_baseline.csv"))
write.csv(df_table1stats, file.path(output_dir, "table1_baseline_stats_full.csv"), row.names = FALSE)
cat("Table 1 exported as .csv files in", output_dir, "\n")
# ---- Table 2: Anthropometry & Body Composition (Adjusted) ----
vars_table2 <- c('height','weight','Waistcir','Hipcir','bmi','ac','whr',
'pbcm','pbf','bmr','tbw_ffm','ecw_tcw','PA50_total')
covars <- c("AGE", "SEX", "EDUYR")
units_table2 <- c(height = "cm", weight = "kg", Waistcir = "cm", Hipcir = "cm", sysbp = "mmHg", diabp = "mmHg",
bmi = "kg/m2", ac = "", whr = "", pbcm = "%", pbf = "%", bmr = "kcal", tbw_ffm = "%", ecw_tcw = "%", PA50_total = "degree")
get_sample_size <- function(df, v, lvl) sum(!is.na(df[[v]]) & df[[group_var]] == lvl)
get_missing_pct_tbl <- function(df, v, lvl) mean(is.na(df[[v]]) & df[[group_var]] == lvl) * 100
get_ancova_table <- function(varlist, groupvar, covars, df, units = NULL) {
lapply(varlist, function(v) {
fml <- as.formula(paste(v, "~", groupvar, "+", paste(covars, collapse = " + ")))
model <- lm(fml, data = df, na.action = na.exclude)
emm <- emmeans(model, groupvar)
summary_emm <- summary(emm, level = 0.95)
contrasts <- summary(contrast(emm, method = "pairwise"), infer = TRUE)
aovm <- tryCatch(anova(model), error = function(e) NULL)
eta2 <- tryCatch({
ss_group <- aovm[groupvar, "Sum Sq"]
ss_total <- sum(aovm[,"Sum Sq"])
ss_group/ss_total
}, error = function(e) NA)
adj_r2 <- tryCatch(summary(model)$adj.r.squared, error = function(e) NA)
g1 <- levels(df[[group_var]])[1]
g2 <- levels(df[[group_var]])[2]
n1 <- get_sample_size(df, v, g1)
n2 <- get_sample_size(df, v, g2)
miss1 <- get_missing_pct_tbl(df, v, g1)
miss2 <- get_missing_pct_tbl(df, v, g2)
tibble(
Variable = v,
Unit = if (!is.null(units) && !is.na(units[v])) units[v] else "",
N_StableCN = n1,
N_CNtransitMCI = n2,
StableCN_AdjMean_CI = sprintf("%.2f (%.2f, %.2f)", summary_emm$emmean[summary_emm[[groupvar]] == g1],
summary_emm$lower.CL[summary_emm[[groupvar]] == g1],
summary_emm$upper.CL[summary_emm[[groupvar]] == g1]),
CNtransitMCI_AdjMean_CI = sprintf("%.2f (%.2f, %.2f)", summary_emm$emmean[summary_emm[[groupvar]] == g2],
summary_emm$lower.CL[summary_emm[[groupvar]] == g2],
summary_emm$upper.CL[summary_emm[[groupvar]] == g2]),
Diff_CI = sprintf("%.2f (%.2f, %.2f)", contrasts$estimate[1], contrasts$lower.CL[1], contrasts$upper.CL[1]),
SE = round(contrasts$SE[1],2),
PValue = round(contrasts$p.value[1],4),
EtaSq = round(eta2,3),
Adj_R2 = round(adj_r2,3),
Miss_StableCN = round(miss1,2),
Miss_CNtransitMCI = round(miss2,2)
)
}) %>% bind_rows()
}
tbl2_journal <- get_ancova_table(vars_table2, group_var, covars, df_baseline, units_table2)
write.csv(tbl2_journal, file.path(output_dir, "table2_journalformat_full.csv"), row.names = FALSE)
cat("Table 2 exported as .csv file in", output_dir, "\n")
# ---- Table 3: Segmental Variables (Adjusted) ----
vars_table3 <- c('ECW_ICW_upper','ECW_ICW_lower','Water_Lean_upper','Water_Lean_lower',
'R_upper','R_lower','Xc_upper','Xc_lower','PA_upper','PA_lower',
'R_H_upper','R_H_lower','Xc_H_upper','Xc_H_lower')
units_table3 <- c(
ECW_ICW_upper = "%", ECW_ICW_lower = "%", Water_Lean_upper = "%", Water_Lean_lower = "%",
R_upper = "Ohm", R_lower = "Ohm", Xc_upper = "Ohm", Xc_lower = "Ohm",
PA_upper = "degree", PA_lower = "degree", R_H_upper = "Ohm", R_H_lower = "Ohm",
Xc_H_upper = "Ohm", Xc_H_lower = "Ohm"
)
tbl3_journal <- get_ancova_table(vars_table3, group_var, covars, df_baseline, units_table3)
write.csv(tbl3_journal, file.path(output_dir, "table3_journalformat_full.csv"), row.names = FALSE)
cat("Table 3 exported as .csv file in", output_dir, "\n")
# Data manipulation
library(dplyr)
library(tidyr)
library(tibble)
library(lubridate)
library(stringr)
# Visualization
library(ggplot2)
library(cowplot)
library(ggpubr)
library(patchwork)
library(sjPlot)
# Statistical analysis
library(lme4)
library(rstatix)
library(effectsize)
library(emmeans)
library(broom)
library(broom.mixed)
# Reporting
library(gtsummary)
library(flextable)
library(summarytools)
library(tableone)
library(effsize)
df <- read.csv("Chosun5yBIApreprocess.csv", stringsAsFactors = FALSE)
remove_list <- c("a_458", "a_525", "F_278", "a_031", "C_124", "F_043")
df <- df %>% filter(!(k_no %in% remove_list))
df <- df %>%
mutate(datetest = as.Date(datetest, format = "%m/%d/%Y"))
df2 <- df %>%
group_by(USUBJID) %>%
filter(n() >= 2) %>%
ungroup()
df2 <- df2 %>%
arrange(USUBJID, datetest)
df3 <- df2 %>%
group_by(USUBJID) %>%
mutate(
Initial_Status = first(diagnosis),
Final_Status = last(diagnosis),
Transition     = paste(Initial_Status, "-", Final_Status),
Change_Type    = case_when(
Initial_Status == "CN"  & Final_Status == "CN"  ~ "StableCN",
Initial_Status == "CN"  & Final_Status == "MCI" ~ "CNtransitMCI",
Initial_Status == "MCI" & Final_Status == "CN"  ~ "MCItransitCN",
Initial_Status == "MCI" & Final_Status == "MCI" ~ "StableMCI",
Initial_Status == "MCI" & Final_Status == "AD"  ~ "MCItransitAD",
Initial_Status == "CN"  & Final_Status == "AD"  ~ "CNtransitAD",
Initial_Status == "AD"  & Final_Status == "MCI" ~ "ADtransitMCI",
Initial_Status == "AD"  & Final_Status == "CN"  ~ "ADtransitCN",
Initial_Status == "AD"  & Final_Status == "AD"  ~ "StableAD",
TRUE ~ NA_character_
),
visit_count = n(),
baseline_date = first(datetest),
elapsed_years = as.numeric(difftime(datetest, baseline_date, units = "days")) / 365.25,
elapsed_years_First_to_Last = as.numeric(difftime(last(datetest), first(datetest), units = "days")) / 365.25
) %>%
ungroup()
df4 <- df3 %>%
filter(elapsed_years_First_to_Last >= 0.916666666)
#write.csv(df4, "df4.csv",row.names = FALSE)
